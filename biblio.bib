@article{zhang_hierarchical_2021,
	title = {Hierarchical deep-learning neural networks: finite elements and beyond},
	volume = {67},
	issn = {1432-0924},
	shorttitle = {Hierarchical deep-learning neural networks},
	url = {https://doi.org/10.1007/s00466-020-01928-9},
	doi = {10.1007/s00466-020-01928-9},
	language = {en},
	number = {1},
	urldate = {2024-01-08},
	journal = {Computational Mechanics},
	author = {Zhang, Lei and Cheng, Lin and Li, Hengyang and Gao, Jiaying and Yu, Cheng and Domel, Reno and Yang, Yang and Tang, Shaoqiang and Liu, Wing Kam},
	month = jan,
	year = {2021},
	keywords = {Data-driven, Fundamental building block, Neural network interpolation functions, r- and rh-adaptivity, Rational functions (i.e. RKPM, NURBS and IGA)},
	pages = {207--230},
	file = {Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/JMBGIRST/Zhang et al. - 2021 - Hierarchical deep-learning neural networks finite.pdf:application/pdf},
}


@article{zhang_hidenn-td_2022,
	title = {{HiDeNN}-{TD}: {Reduced}-order hierarchical deep learning neural networks},
	volume = {389},
	issn = {0045-7825},
	shorttitle = {{HiDeNN}-{TD}},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782521006629},
	doi = {10.1016/j.cma.2021.114414},
	abstract = {This paper presents a tensor decomposition (TD) based reduced-order model of the hierarchical deep-learning neural networks (HiDeNN). The proposed HiDeNN-TD method keeps advantages of both HiDeNN and TD methods. The automatic mesh adaptivity makes the HiDeNN-TD more accurate than the finite element method (FEM) and conventional proper generalized decomposition (PGD) and TD, using a fraction of the FEM degrees of freedom. This work focuses on the theoretical foundation of the method. Hence, the accuracy and convergence of the method have been studied theoretically and numerically, with a comparison to different methods, including FEM, PGD, TD, HiDeNN and Deep Neural Networks. In addition, we have theoretically shown that the PGD/TD converges to FEM at increasing modes, and the PGD/TD solution error is a summation of the mesh discretization error and the mode reduction error. The proposed HiDeNN-TD shows a high accuracy with orders of magnitude fewer degrees of freedom than FEM, and hence a high potential to achieve fast computations with a high level of accuracy for large-size engineering and scientific problems. As a trade-off between accuracy and efficiency, we propose a highly efficient solution strategy called HiDeNN-PGD. Although the solution is less accurate than HiDeNN-TD, HiDeNN-PGD still provides a higher accuracy than PGD/TD and FEM with only a small amount of additional cost to PGD.},
	urldate = {2023-12-26},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Zhang, Lei and Lu, Ye and Tang, Shaoqiang and Liu, Wing Kam},
	month = feb,
	year = {2022},
	keywords = {Canonical tensor decomposition, Convergence study and error bound, Hierarchical deep-learning neural networks, Proper generalized decomposition, Reduced order finite element method},
	pages = {114414},
	file = {Submitted Version:/Users/daby/Documents/biblio/Zotero_data/storage/BP5LYYEN/Zhang et al. - 2022 - HiDeNN-TD Reduced-order hierarchical deep learnin.pdf:application/pdf;Zhang et al. - 2022 - HiDeNN-TD Reduced-order hierarchical deep learnin.pdf:/Users/daby/Documents/biblio/Zotero_data/storage/C6RNIRIT/Zhang et al. - 2022 - HiDeNN-TD Reduced-order hierarchical deep learnin.pdf:application/pdf},
}


@article{chinesta_short_2011,
	title = {A {Short} {Review} on {Model} {Order} {Reduction} {Based} on {Proper} {Generalized} {Decomposition}},
	volume = {18},
	issn = {1134-3060, 1886-1784},
	url = {http://link.springer.com/10.1007/s11831-011-9064-7},
	doi = {10.1007/s11831-011-9064-7},
	abstract = {This paper revisits a new model reduction methodology based on the use of separated representations, the so called Proper Generalized Decomposition—PGD. Space and time separated representations generalize Proper Orthogonal Decompositions—POD—avoiding any a priori knowledge on the solution in contrast to the vast majority of POD based model reduction technologies as well as reduced bases approaches. Moreover, PGD allows to treat efﬁciently models deﬁned in degenerated domains as well as the multidimensional models arising from multidimensional physics (quantum chemistry, kinetic theory descriptions, . . .) or from the standard ones when some sources of variability are introduced in the model as extra-coordinates.},
	language = {en},
	number = {4},
	urldate = {2021-04-06},
	journal = {Archives of Computational Methods in Engineering},
	author = {Chinesta, Francisco and Ladeveze, Pierre and Cueto, Elías},
	month = nov,
	year = {2011},
	pages = {395--404},
	file = {Chinesta et al. - 2011 - A Short Review on Model Order Reduction Based on P.pdf:/Users/daby/Documents/biblio/Zotero_data/storage/7RG7QRDY/Chinesta et al. - 2011 - A Short Review on Model Order Reduction Based on P.pdf:application/pdf},
}



@article{ryckelynck_thea_2006,
	title = {On thea priori model reduction: {Overview} and recent developments},
	volume = {13},
	issn = {1886-1784},
	shorttitle = {On thea priori model reduction},
	url = {https://doi.org/10.1007/BF02905932},
	doi = {10.1007/BF02905932},
	abstract = {Karhunen-Loève expansion and snapshot POD are based on principal component analysis of series of data. They provide basis vectors of the subspace spanned by the data. All the data must be taken into account to find the basis vectors. These methods are not convenient for any improvement of the basis vectors when new data are added into the data base. We consider the data as a state evolution and we propose an incremental algorithm to build basis functions for the decomposition of this state evolution. The proposed algorithm is based on the APHR method (A Priori Hyper-Reduction method). This is an adaptive strategy to build reduced order model when the state evolution is implicitely defined by non-linear governing equations. In case of known state evolutions the APHR method is an incremental Karhunen-Loève decomposition. This approach is very convenient to expand the subspace spanned by the basis functions. In the first part of the present paper the main concepts related to the “a priori” model reduction technique are revisited, as a previous task to its application in the cases considered in the next sections.},
	language = {en},
	number = {1},
	urldate = {2024-02-01},
	journal = {Archives of Computational Methods in Engineering},
	author = {Ryckelynck, D. and Chinesta, F. and Cueto, E. and Ammar, A.},
	month = mar,
	year = {2006},
	keywords = {Essential Boundary Condition, Model Reduction, Orientation Distribution Function, Proper Orthogonal Decomposition, State Evolution},
	pages = {91--128},
	file = {Submitted Version:/Users/daby/Documents/biblio/Zotero_data/storage/PIEU4DED/Ryckelynck et al. - 2006 - On thea priori model reduction Overview and recen.pdf:application/pdf},
}


@article{liu_hidenn-fem_2023,
	title = {{HiDeNN}-{FEM}: a seamless machine learning approach to nonlinear finite element analysis},
	volume = {72},
	issn = {1432-0924},
	shorttitle = {{HiDeNN}-{FEM}},
	url = {https://doi.org/10.1007/s00466-023-02293-z},
	doi = {10.1007/s00466-023-02293-z},
	abstract = {The hierarchical deep-learning neural network (HiDeNN) (Zhang et al. Computational Mechanics, 67:207–230) provides a systematic approach to constructing numerical approximations that can be incorporated into a wide variety of Partial differential equations (PDE) and/or Ordinary differential equations (ODE) solvers. This paper presents a framework of the nonlinear finite element based on HiDeNN approximation (nonlinear HiDeNN-FEM). This is enabled by three basic building blocks employing structured deep neural networks: (1) A partial derivative operator block that performs the differentiation of the shape functions with respect to the element coordinates, (2) An r-adaptivity block that improves the local and global convergence properties and (3) A materials derivative block that evaluates the material derivatives of the shape function. While these building blocks can be applied to any element, specific implementations are presented in 1D and 2D to illustrate the application of the deep learning neural network. Two-step optimization schemes are further developed to allow for the capabilities of r-adaptivity and easy integration with any existing FE solver. Numerical examples of 2D and 3D demonstrate that the proposed nonlinear HiDeNN-FEM with r-adaptivity provides much higher accuracy than regular FEM. It also significantly reduces element distortion and suppresses the hourglass mode.},
	language = {en},
	number = {1},
	urldate = {2023-12-24},
	journal = {Computational Mechanics},
	author = {Liu, Yingjian and Park, Chanwook and Lu, Ye and Mojumder, Satyajit and Liu, Wing Kam and Qian, Dong},
	month = jul,
	year = {2023},
	keywords = {Data-driven, Hierarchical deep neural network, Nonlinear finite element method, r-adaptivity, Shape function},
	pages = {173--194},
	file = {Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/ZZ7K9CFT/Liu et al. - 2023 - HiDeNN-FEM a seamless machine learning approach t.pdf:application/pdf},
}




@article{kramer_learning_2024,
	title = {Learning {Nonlinear} {Reduced} {Models} from {Data} with {Operator} {Inference}},
	volume = {56},
	url = {https://doi.org/10.1146/annurev-fluid-121021-025220},
	doi = {10.1146/annurev-fluid-121021-025220},
	abstract = {This review discusses Operator Inference, a nonintrusive reduced modeling approach that incorporates physical governing equations by defining a structured polynomial form for the reduced model, and then learns the corresponding reduced operators from simulated training data. The polynomial model form of Operator Inference is sufficiently expressive to cover a wide range of nonlinear dynamics found in fluid mechanics and other fields of science and engineering, while still providing efficient reduced model computations. The learning steps of Operator Inference are rooted in classical projection-based model reduction; thus, some of the rich theory of model reduction can be applied to models learned with Operator Inference. This connection to projection-based model reduction theory offers a pathway toward deriving error estimates and gaining insights to improve predictions. Furthermore, through formulations of Operator Inference that preserve Hamiltonian and other structures, important physical properties such as energy conservation can be guaranteed in the predictions of the reduced model beyond the training horizon. This review illustrates key computational steps of Operator Inference through a large-scale combustion example.},
	number = {1},
	urldate = {2024-02-06},
	journal = {Annual Review of Fluid Mechanics},
	author = {Kramer, Boris and Peherstorfer, Benjamin and Willcox, Karen E.},
	year = {2024},
	note = {\_eprint: https://doi.org/10.1146/annurev-fluid-121021-025220},
	keywords = {data-driven modeling, nonlinear model reduction, Operator Inference, scientific machine learning, structure preservation},
	pages = {521--548},
	file = {Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/W9KCXZR4/Kramer et al. - 2024 - Learning Nonlinear Reduced Models from Data with O.pdf:application/pdf},
}



@misc{geelen_learning_2023,
	title = {Learning physics-based reduced-order models from data using nonlinear manifolds},
	url = {http://arxiv.org/abs/2308.02802},
	abstract = {We present a novel method for learning reduced-order models of dynamical systems using nonlinear manifolds. First, we learn the manifold by identifying nonlinear structure in the data through a general representation learning problem. The proposed approach is driven by embeddings of low-order polynomial form. A projection onto the nonlinear manifold reveals the algebraic structure of the reduced-space system that governs the problem of interest. The matrix operators of the reduced-order model are then inferred from the data using operator inference. Numerical experiments on a number of nonlinear problems demonstrate the generalizability of the methodology and the increase in accuracy that can be obtained over reduced-order modeling methods that employ a linear subspace approximation.},
	urldate = {2024-02-06},
	publisher = {arXiv},
	author = {Geelen, Rudy and Balzano, Laura and Wright, Stephen and Willcox, Karen},
	month = aug,
	year = {2023},
	note = {arXiv:2308.02802 [cs, math]},
	keywords = {Mathematics - Numerical Analysis},
	file = {arXiv.org Snapshot:/Users/daby/Documents/biblio/Zotero_data/storage/N5Y2W635/2308.html:text/html;Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/F3TJYNRT/Geelen et al. - 2023 - Learning physics-based reduced-order models from d.pdf:application/pdf},
}


@article{geelen_learning_2024,
	title = {Learning physics-based reduced-order models from data using nonlinear manifolds},
	volume = {34},
	issn = {1054-1500},
	url = {https://doi.org/10.1063/5.0170105},
	doi = {10.1063/5.0170105},
	abstract = {We present a novel method for learning reduced-order models of dynamical systems using nonlinear manifolds. First, we learn the manifold by identifying nonlinear structure in the data through a general representation learning problem. The proposed approach is driven by embeddings of low-order polynomial form. A projection onto the nonlinear manifold reveals the algebraic structure of the reduced-space system that governs the problem of interest. The matrix operators of the reduced-order model are then inferred from the data using operator inference. Numerical experiments on a number of nonlinear problems demonstrate the generalizability of the methodology and the increase in accuracy that can be obtained over reduced-order modeling methods that employ a linear subspace approximation.},
	number = {3},
	urldate = {2024-05-06},
	journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
	author = {Geelen, Rudy and Balzano, Laura and Wright, Stephen and Willcox, Karen},
	month = mar,
	year = {2024},
	pages = {033122},
	file = {Snapshot:/Users/daby/Documents/biblio/Zotero_data/storage/7RJ59LGN/Learning-physics-based-reduced-order-models-from.html:text/html;Submitted Version:/Users/daby/Documents/biblio/Zotero_data/storage/LJU2XDQR/Geelen et al. - 2024 - Learning physics-based reduced-order models from d.pdf:application/pdf},
}


@article{park_convolution_2023,
	title = {Convolution hierarchical deep-learning neural network ({C}-{HiDeNN}) with graphics processing unit ({GPU}) acceleration},
	volume = {72},
	issn = {1432-0924},
	url = {https://doi.org/10.1007/s00466-023-02329-4},
	doi = {10.1007/s00466-023-02329-4},
	abstract = {We propose the Convolution Hierarchical Deep-learning Neural Network (C-HiDeNN) that can be tuned to have superior accuracy, higher smoothness, and faster convergence rates like higher order finite element methods (FEM) while using only linear element’s degrees of freedom. This is based on our newly developed convolution interpolation theory (Lu et al. in Comput Mech, 2023) and this article focuses on the deep-learning interpretation of C-HiDeNN with graphics processing unit (GPU) programming using JAX library in Python. Instead of increasing the degrees of freedom like higher order FEM, C-HiDeNN takes advantage of neighboring elements to construct the so-called convolution patch functions. The computational overhead of C-HiDeNN is reduced by GPU programming and the total solution time is brought down to the same order as commercial FEM software running on a CPU, however, with orders of magnitude better accuracy and faster convergence rates. C-HiDeNN is locking-free regardless of element types (even with 3-node triangular elements or 4-node tetrahedral elements). C-HiDeNN is also capable of r-h-p-mesh adaptivity like its predecessor HiDeNN (Zhang et al. in Comput Mech 67:207–230, 2021) with additional “a” (dilation parameter) adaptivity that stems from the convolution patch function and “p” adaptivity with higher accuracy and with the same degrees of freedom as that of the linear finite elements. C-HiDeNN potentially has myriad future applications in multiscale analysis, additive and advanced manufacturing process simulations, and high-resolution topology optimization. Details on these applications can be found in the companion papers (Lu et al. 2023; Saha et al. in Comput Mech, 2023; Li et al. in Comput Mech, 2023) published in this special issue.},
	language = {en},
	number = {2},
	urldate = {2024-01-30},
	journal = {Computational Mechanics},
	author = {Park, Chanwook and Lu, Ye and Saha, Sourav and Xue, Tianju and Guo, Jiachen and Mojumder, Satyajit and Apley, Daniel W. and Wagner, Gregory J. and Liu, Wing Kam},
	month = aug,
	year = {2023},
	keywords = {Convolution and graph theories, Deep-learning neural networks, Finite element and meshfree methods, Graphics processing unit (GPU), Partition of unity},
	pages = {383--409},
}



@article{giacoma_toward_2015,
	title = {Toward an optimal a priori reduced basis strategy for frictional contact problems with {LATIN} solver},
	volume = {283},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782514003144},
	doi = {10.1016/j.cma.2014.09.005},
	abstract = {In this paper, an efficient a priori model reduction strategy for frictional contact problems is presented. We propose to solve this problem by using the finite element method and the non-linear LATIN solver. Basically, this non-linear solver assumes a space–time separated representation presaging nowadays PGD strategies. We extend this family of solvers to frictional engineering applications with reduced subspaces and no prior knowledge about the solution (contrary to a posteriori model reduction techniques). Hereinafter, a hybrid a priori/a posteriori LATIN-PGD formulation for frictional contact problems is proposed. Indeed, the suggested algorithm may or may not start with an initial guess of the reduced basis and is able to enrich the basis in order to reach a given level of accuracy. Moreover, it provides progressively the solution of the considered problem into a quasi-optimal space–time separated form compared to the singular value decomposition (SVD). Some examples are provided in order to illustrate the efficiency and quasi-optimality of the proposed a priori reduced basis LATIN solver.},
	language = {en},
	urldate = {2023-07-04},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Giacoma, A. and Dureisseix, D. and Gravouil, A. and Rochette, M.},
	month = jan,
	year = {2015},
	keywords = {LATIN method, Frictional contact, Proper Generalized Decomposition (PGD), Reduced Order model},
	pages = {1357--1381},
	file = {ScienceDirect Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/4Q7VPYZN/Giacoma et al. - 2015 - Toward an optimal a priori reduced basis strategy .pdf:application/pdf;ScienceDirect Snapshot:/Users/daby/Documents/biblio/Zotero_data/storage/N68YQKB8/S0045782514003144.html:text/html},
}



@article{bachmayr_tensor_2016,
	title = {Tensor {Networks} and {Hierarchical} {Tensors} for the {Solution} of {High}-{Dimensional} {Partial} {Differential} {Equations}},
	volume = {16},
	issn = {1615-3383},
	url = {https://doi.org/10.1007/s10208-016-9317-9},
	doi = {10.1007/s10208-016-9317-9},
	abstract = {Hierarchical tensors can be regarded as a generalisation, preserving many crucial features, of the singular value decomposition to higher-order tensors. For a given tensor product space, a recursive decomposition of the set of coordinates into a dimension tree gives a hierarchy of nested subspaces and corresponding nested bases. The dimensions of these subspaces yield a notion of multilinear rank. This rank tuple, as well as quasi-optimal low-rank approximations by rank truncation, can be obtained by a hierarchical singular value decomposition. For fixed multilinear ranks, the storage and operation complexity of these hierarchical representations scale only linearly in the order of the tensor. As in the matrix case, the set of hierarchical tensors of a given multilinear rank is not a convex set, but forms an open smooth manifold. A number of techniques for the computation of hierarchical low-rank approximations have been developed, including local optimisation techniques on Riemannian manifolds as well as truncated iteration methods, which can be applied for solving high-dimensional partial differential equations. This article gives a survey of these developments. We also discuss applications to problems in uncertainty quantification, to the solution of the electronic Schrödinger equation in the strongly correlated regime, and to the computation of metastable states in molecular dynamics.},
	language = {en},
	number = {6},
	urldate = {2024-03-29},
	journal = {Foundations of Computational Mathematics},
	author = {Bachmayr, Markus and Schneider, Reinhold and Uschmajew, André},
	month = dec,
	year = {2016},
	keywords = {35C, 49M, 65-02, 65F99, 65J, Hierarchical tensors, High-dimensional partial differential equations, Low-rank approximation},
	pages = {1423--1472},
	file = {Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/PCZLDWCB/Bachmayr et al. - 2016 - Tensor Networks and Hierarchical Tensors for the S.pdf:application/pdf},
}


@article{zniyed_tt-based_2020,
	title = {A {TT}-{Based} {Hierarchical} {Framework} for {Decomposing} {High}-{Order} {Tensors}},
	volume = {42},
	issn = {1064-8275},
	url = {https://epubs.siam.org/doi/abs/10.1137/18M1229973},
	doi = {10.1137/18M1229973},
	abstract = {Recent achievements in the field of tensor product approximation provide promising new formats for the representation of tensors in form of tree tensor networks. In contrast to the canonical r-term representation (CANDECOMP, PARAFAC), these new formats provide stable representations, while the amount of required data is only slightly larger. The tensor train (TT) format [SIAM J. Sci. Comput., 33 (2011), pp. 2295–2317], a simple special case of the hierarchical Tucker format [J. Fourier Anal. Appl., 5 (2009), p. 706], is a useful prototype for practical low-rank tensor representation. In this article, we show how optimization tasks can be treated in the TT format by a generalization of the well-known alternating least squares (ALS) algorithm and by a modified approach (MALS) that enables dynamical rank adaptation. A formulation of the component equations in terms of so-called retraction operators helps to show that many structural properties of the original problems transfer to the micro-iterations, giving what is to our knowledge the first stable generic algorithm for the treatment of optimization tasks in the tensor format. For the examples of linear equations and eigenvalue equations, we derive concrete working equations for the micro-iteration steps; numerical examples confirm the theoretical results concerning the stability of the TT decomposition and of ALS and MALS but also show that in some cases, high TT ranks are required during the iterative approximation of low-rank tensors, showing some potential of improvement.},
	number = {2},
	urldate = {2024-03-29},
	journal = {SIAM Journal on Scientific Computing},
	author = {Zniyed, Yassine and Boyer, Rémy and de Almeida, André L. F. and Favier, Gérard},
	month = jan,
	year = {2020},
	note = {Publisher: Society for Industrial and Applied Mathematics},
	pages = {A822--A848},
	file = {Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/6AMUEDEF/Zniyed et al. - 2020 - A TT-Based Hierarchical Framework for Decomposing .pdf:application/pdf},
}



@article{guo_doing_2014,
	title = {Doing {Topology} {Optimization} {Explicitly} and {Geometrically}—{A} {New} {Moving} {Morphable} {Components} {Based} {Framework}},
	volume = {81},
	issn = {0021-8936},
	url = {https://doi.org/10.1115/1.4027609},
	doi = {10.1115/1.4027609},
	number = {081009},
	urldate = {2024-04-02},
	journal = {Journal of Applied Mechanics},
	author = {Guo, Xu and Zhang, Weisheng and Zhong, Wenliang},
	month = may,
	year = {2014},
	file = {Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/JUZ5B2DZ/Guo et al. - 2014 - Doing Topology Optimization Explicitly and Geometr.pdf:application/pdf;Snapshot:/Users/daby/Documents/biblio/Zotero_data/storage/LSBJR3RW/Doing-Topology-Optimization-Explicitly-and.html:text/html},
}



@article{nouy_priori_2010,
	title = {A priori model reduction through {Proper} {Generalized} {Decomposition} for solving time-dependent partial differential equations},
	volume = {199},
	issn = {00457825},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782510000186},
	doi = {10.1016/j.cma.2010.01.009},
	abstract = {Over the past years, model reduction techniques have become a necessary path for the reduction of computational requirements in the numerical simulation of complex models. A family of a priori model reduction techniques, called Proper Generalized Decomposition (PGD) methods, are receiving a growing interest. These methods rely on the a priori construction of separated variables representations of the solution of models deﬁned in tensor product spaces. They can be interpreted as generalizations of Proper Orthogonal Decomposition (POD) for the a priori construction of such separated representations. In this paper, we introduce and study different deﬁnitions of PGD for the solution of time-dependent partial differential equations. We review classical deﬁnitions of PGD based on Galerkin or Minimal Residual formulations and we propose and discuss several improvements for these classical deﬁnitions. We give an interpretation of optimal decompositions as the solution of pseudo-eigenproblems. We also introduce a new deﬁnition of PGD, called Minimax PGD, which can be interpreted as a Petrov–Galerkin model reduction technique, where test and trial reduced basis functions are related by an adjoint problem. This new deﬁnition improves convergence properties of separated representations with respect to a chosen metric. It coincides with a classical POD for degenerate time-dependent partial differential equations. For the numerical construction of each PGD, we propose algorithms inspired from the solution of eigenproblems. Several numerical examples illustrate and compare the different deﬁnitions of PGD on transient advection–diffusion–reaction equations.},
	language = {en},
	number = {23-24},
	urldate = {2022-04-15},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Nouy, Anthony},
	month = apr,
	year = {2010},
	pages = {1603--1626},
	file = {Nouy - 2010 - A priori model reduction through Proper Generalize.pdf:/Users/daby/Documents/biblio/Zotero_data/storage/UYRPDAW2/Nouy - 2010 - A priori model reduction through Proper Generalize.pdf:application/pdf},
}



@article{lu_adaptive_2018,
	title = {Adaptive sparse grid based {HOPGD}: {Toward} a nonintrusive strategy for constructing space-time welding computational vademecum},
	volume = {114},
	copyright = {Copyright © 2018 John Wiley \& Sons, Ltd.},
	issn = {1097-0207},
	shorttitle = {Adaptive sparse grid based {HOPGD}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nme.5793},
	doi = {10.1002/nme.5793},
	abstract = {Simulation-based engineering usually needs the construction of computational vademecum to take into account the multiparametric aspect. One example concerns the optimization and inverse identification problems encountered in welding processes. This paper presents a nonintrusive a posteriori strategy for constructing quasi-optimal space-time computational vademecum using the higher-order proper generalized decomposition method. Contrary to conventional tensor decomposition methods, based on full grids (eg, parallel factor analysis/higher-order singular value decomposition), the proposed method is adapted to sparse grids, which allows an efficient adaptive sampling in the multidimensional parameter space. In addition, a residual-based accelerator is proposed to accelerate the higher-order proper generalized decomposition procedure for the optimal aspect of computational vademecum. Based on a simplified welding model, different examples of computational vademecum of dimension up to 6, taking into account both geometry and material parameters, are presented. These vademecums lead to real-time parametric solutions and can serve as handbook for engineers to deal with optimization, identification, or other problems related to repetitive task.},
	language = {en},
	number = {13},
	urldate = {2024-04-10},
	journal = {International Journal for Numerical Methods in Engineering},
	author = {Lu, Y. and Blal, N. and Gravouil, A.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/nme.5793},
	keywords = {adaptive sparse grid, HOPGD, nonintrusive, nonlinear thermomechanical problems},
	pages = {1438--1461},
	file = {Full Text PDF:/Users/daby/Documents/biblio/Zotero_data/storage/GEWT5VLF/Lu et al. - 2018 - Adaptive sparse grid based HOPGD Toward a nonintr.pdf:application/pdf;Snapshot:/Users/daby/Documents/biblio/Zotero_data/storage/W7XT37MT/nme.html:text/html},
}


@article{galland_global_2011,
	title = {A global model reduction approach for {3D} fatigue crack growth with confined plasticity},
	volume = {200},
	issn = {0045-7825},
	url = {https://www.sciencedirect.com/science/article/pii/S0045782510002756},
	doi = {10.1016/j.cma.2010.08.018},
	abstract = {It has been known for decades that fatigue crack propagation in elastic–plastic media is very sensitive to load history since the nonlinear behavior of the material can have a great influence on propagation rates. However, raw computations of millions of nonlinear fatigue cycles on tridimensional structures would lead to prohibitive calculation times. In this respect, we propose a global model reduction strategy, mixing both the a posteriori and a priori approaches in order to drastically decrease the computational cost of these types of problems.},
	number = {5},
	urldate = {2024-04-10},
	journal = {Computer Methods in Applied Mechanics and Engineering},
	author = {Galland, F. and Gravouil, A. and Malvesin, E. and Rochette, M.},
	month = jan,
	year = {2011},
	keywords = {Closure effect, Crack propagation, Fatigue, Model reduction, Reduced basis, Small scale yielding},
	pages = {699--716},
	file = {Galland et al. - 2011 - A global model reduction approach for 3D fatigue c.pdf:/Users/daby/Documents/biblio/Zotero_data/storage/7TNF4966/Galland et al. - 2011 - A global model reduction approach for 3D fatigue c.pdf:application/pdf;ScienceDirect Snapshot:/Users/daby/Documents/biblio/Zotero_data/storage/GRNK8UGV/S0045782510002756.html:text/html},
}

@article{DabyHybrid,
	title = {A hybrid frequency-temporal reduced-order method for nonlinear dynamics},
	volume = {111},
	issn = {1573-269X},
	url = {https://doi.org/10.1007/s11071-023-08513-8},
	doi = {10.1007/s11071-023-08513-8},
	abstract = {Solving dynamics problem in the frequency domain gives significant advantages compared with solutions fully computed in the temporal domain, but history-dependent nonlinear behaviour is an obstacle to employ that strategy. A hybrid approach is proposed to solve the nonlinear behaviour in the temporal domain, while the mechanical equilibrium is solved using a frequency strategy coupled with model-order reduction methods. In order to employ the fast Fourier transform (FFT) robustly for the transient regime, artificial numerical damping is used. The reduced-order hybrid temporal-frequency approach is investigated for two- and three-dimensional applications; it appears as a robust and proficient technique to simulate structures under transient dynamic loadings until failure.},
	language = {en},
	number = {15},
	journal = {Nonlinear Dynamics},
	author = {Daby-Seesaram, A. and Fau, A. and Charbonnel, P.-É. and Néron, D.},
	month = aug,
	year = {2023},
	keywords = {Damage, Frequency approach, LATIN-PGD, Nonlinear behaviour, Reduced-order modelling, Transient dynamics},
	pages = {13669--13689},
	file = {Full Text PDF:/u/daby/Documents/These_Nexcloud/Biblio/Zotero_data/storage/QI8HZBZ7/Daby-Seesaram et al. - 2023 - A hybrid frequency-temporal reduced-order method f.pdf:application/pdf},
}